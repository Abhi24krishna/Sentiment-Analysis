{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import nltk\n",
    "import re,csv\n",
    "import string\n",
    "from nltk.classify import *\n",
    "import nltk.classify.util\n",
    "\n",
    "#initialize stopWords\n",
    "stopWords = []\n",
    " \n",
    "def replaceTwoOrMore(s):\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", s)\n",
    "\n",
    "def getStopWordList(stopWordListFileName):\n",
    "    stopWords=[]\n",
    "    stopWords.append('URL')\n",
    " \n",
    "    fp = open(stopWordListFileName, 'r')\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        word = line.strip()\n",
    "        stopWords.append(word)\n",
    "        line = fp.readline()\n",
    "    fp.close()\n",
    "    return stopWords\n",
    "\n",
    "st = open('StopWords.txt', 'r')\n",
    "stopWords = getStopWordList('StopWords.txt')\n",
    "  \n",
    "def getFeatureVector(tweet):\n",
    "    featureVector = []\n",
    "    words = tweet.split()\n",
    "    for w in words:\n",
    "        #Preprocessing\n",
    "        w = replaceTwoOrMore(w)\n",
    "        w = w.strip('\\'\"?,.')\n",
    "        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w)\n",
    "        if(w in stopWords or val is None):\n",
    "            continue\n",
    "        else:\n",
    "            featureVector.append(w.lower())\n",
    "    return featureVector\n",
    " \n",
    "def featureExtraction():\n",
    "    #Reading Tweets\n",
    "    inpTweets = csv.reader(open('abhi.txt', 'rt'), delimiter=',', quotechar='|')\n",
    "    tweets = []\n",
    "    \n",
    "    for rowTweet in inpTweets:\n",
    "        sentiment = rowTweet[0]\n",
    "        tweet = rowTweet[1]\n",
    "        featureVector = getFeatureVector(tweet)\n",
    "        tweets.append((featureVector, sentiment))\n",
    "    return tweets \n",
    "\n",
    "tweets = featureExtraction()\n",
    "\n",
    "#Classifier \n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (text, sentiment) in tweets:\n",
    "        all_words.extend(text)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    \n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "\n",
    "word_features = get_word_features(get_words_in_tweets(tweets)) \n",
    "\n",
    "def extract_features(tweet):\n",
    "    settweet = set(tweet)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in settweet)\n",
    "    return features\n",
    "\n",
    "\n",
    "training_set = nltk.classify.apply_features(extract_features, tweets[601:5400:])\n",
    "test_set = nltk.classify.apply_features(extract_features, tweets[:600]+tweets[5400:])\n",
    "\n",
    "#****** Naive Bayes Classifier******************************************\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = nltk.classify.accuracy(classifier, training_set) \n",
    "print(accuracy) \n",
    "\n",
    "total = accuracy * 100 \n",
    "print('Naive Bayes Accuracy with Training Set: %4.2f' % total) \n",
    "\n",
    "# Accuracy Test Set\n",
    "accuracyTestSet = nltk.classify.accuracy(classifier, test_set) \n",
    "print(accuracyTestSet)\n",
    "\n",
    "totalTest = accuracyTestSet * 100 \n",
    "print('\\nNaive Bayes Accuracy with the Test Set: %4.2f' % totalTest)\n",
    "\n",
    "print('\\nMost Informative features')\n",
    "print(classifier.show_most_informative_features(n=10))\n",
    "\n",
    "check = ''\n",
    "while(check!='exit'):\n",
    "    inpt = input('\\nProvide Input(string) or Write exit for Exit\\n')\n",
    "    inpt=inpt.lower()\n",
    "    print ('\\n')\n",
    "    if inpt == 'exit':\n",
    "        print ('Exiting the program')\n",
    "        check = 'exit'\n",
    "    else:\n",
    "        inpt = inpt.lower()\n",
    "        inpt = inpt.split()\n",
    "        print ('Predicted Sentiment by Naive Bayes Classifier: ' + classifier.classify(extract_features(inpt)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
